{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project 2\n",
        "Lab journal\n",
        "\n",
        "Aigul Nugmanova\n",
        "\n",
        "Bogdan Sotnikov"
      ],
      "metadata": {
        "id": "l8wv1D4MVbfc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Day 1 02.11.22\n",
        "\n",
        "### Step 1. The preparations.\n",
        "\n",
        "\n",
        "We found the data about [this year vaccine strains of the flu](https://www.fda.gov/vaccines-blood-biologics/lot-release/influenza-vaccine-2022-2023-season). It contains 4 strains:\n",
        "\n",
        ">    A/Victoria/2570/2019 (H1N1)pdm09-like virus;\n",
        "\n",
        ">    A/Darwin/9/2021 (H3N2)-like virus;\n",
        "\n",
        ">    B/Austria/1359417/2021-like virus (B/Victoria lineage); \n",
        "\n",
        ">    B/Phuket/3073/2013-like virus (B/Yamagata lineage).\n",
        "\n",
        "The HI reactions result showed another substrain of flu: \n",
        "> A/Hong Kong/4801/2014 (H3N2)\n",
        "### Step 2. Inspecting the raw data.\n",
        "\n",
        "We downloaded data from [NCBI CRA](http://ftp.sra.ebi.ac.uk/vol1/fastq/SRR170/001/SRR1705851/). We use bash command\n",
        "```bash\n",
        "wget http://ftp.sra.ebi.ac.uk/vol1/fastq/SRR170/001/SRR1705851/\n",
        "```\n",
        "\n",
        "Then we downaloaded reference sequence for hemagglutinine from [NCBI](https://www.ncbi.nlm.nih.gov/nuccore/KF848938.1?report=fasta).\n",
        "\n"
      ],
      "metadata": {
        "id": "iMMcok2KVojh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Day 2 03.11.22\n",
        "### Step 3. Analyzing data.\n",
        "\n",
        "We used fastqc (v. 0.11.9) for analyzing quality of reads.\n",
        "```bash\n",
        "fastqc SRR1705851.fastq.gz\n",
        "```\n",
        "\n",
        "We had warnings in results of fastq analyssis in sections \"Per base sequence content\" and \"Sequence Duplication Levels\". Also we had some bourderline values of tests in \"Per sequence GC content\", \"Sequence Length Distribution\" and \"Overrepresented sequences\". \n",
        "\n",
        "Per sequence GC content bias in the start of figure may be caused by Illuminas' artifacts. The mismatching of nucleotide numbers may be caused of little genome amount.\n",
        "\n",
        "Very high sequence duplication levels may be caused by problems in process of genome library amplification or by sequencing of little fragment of virus NA.\n",
        "\n",
        "For clearing raw data we use trimmomatic (v. 0.39).\n",
        "```bash\n",
        "java -jar /usr/share/java/trimmomatic-0.39.jar SE -phred33 ./SRR1705851.fastq.gz ./SRR1705851_trimmed.fastq.gz LEADING:10 TRAILING:10 SLIDINGWINDOW:10:10\n",
        "```\n",
        "We hadn't seen any significant changes in the fastqc output and number of reads in our data, and next time we worked with first variant of fastq."
      ],
      "metadata": {
        "id": "pT6eyw9KDaek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4. Alignment.\n",
        "\n",
        "In the next step we indexed reference, aligned reads to reference and sorted alignment. For this purposes we used bwa (v. 0.7.17-r1188), samtools (v. 1.16.1) and snakemake (v. 7.17.1). We created file named Snakefile in the working directory and filled it:\n",
        "\n",
        "```bash\n",
        "rule bwa_index:\n",
        "        input:\n",
        "                \"{reference}.fasta\"\n",
        "        output:\n",
        "                \"{reference}.fasta.amb\",\n",
        "                \"{reference}.fasta.ann\",\n",
        "                \"{reference}.fasta.bwt\",\n",
        "                \"{reference}.fasta.pac\",\n",
        "                \"{reference}.fasta.sa\"\n",
        "        shell:\n",
        "                \"bwa index {input}\"\n",
        "\n",
        "rule bwa_mem:\n",
        "        input:\n",
        "                \"{reference}.fasta.amb\",\n",
        "                \"{reference}.fasta.ann\",\n",
        "                \"{reference}.fasta.bwt\",\n",
        "                \"{reference}.fasta.pac\",\n",
        "                \"{reference}.fasta.sa\",\n",
        "                ref = \"{reference}.fasta\",\n",
        "                reads = \"{sample}.fastq.gz\"\n",
        "        output:\n",
        "                \"{reference}.{sample}.unsorted.bam\"\n",
        "        shell:\n",
        "                \"bwa mem {input.ref} {input.reads} | samtools view -b > {output}\"\n",
        "\n",
        "rule sorting_bam:\n",
        "        input:\n",
        "                \"{reference}.{sample}.unsorted.bam\"\n",
        "        output:\n",
        "                \"{reference}.{sample}.sorted.bam\"\n",
        "        shell:\n",
        "                \"samtools sort {input} -o {output}\"\n",
        "\n",
        "```\n",
        "\n",
        "After exiting the vim (sorry for chestnut) we explored the script:\n",
        "```bash\n",
        "snakemake -p --cores all sequence.SRR1705851.sorted.bam\n",
        "```\n",
        "\n",
        "The next stage of our work was indexing the sorted file. The command was:\n",
        "```bash\n",
        "samtools index sequence.SRR1705851.sorted.bam\n",
        "```"
      ],
      "metadata": {
        "id": "cfLrFxsepm0y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Day 3. 07.11.22\n",
        "### Step 5. Preparation for variant calling\n",
        "\n",
        "For pilig up our data from sequncing artifacts we used samtools mpileup. For adequate using of it we need to calculate mean fof the coverage depth. We need to know the total number of mapped reads, average reads' length and length of the reference.\n",
        "\n",
        "The total number of mapped reads we can know using samtools. The command and output are wroten below.\n",
        "\n",
        "```bash\n",
        "samtools flagstat sequence.SRR1705851.unsorted.bam\n",
        "\n",
        "\n",
        "#361349 + 0 in total (QC-passed reads + QC-failed reads)\n",
        "#358265 + 0 primary\n",
        "#0 + 0 secondary\n",
        "#3084 + 0 supplementary\n",
        "#0 + 0 duplicates\n",
        "#0 + 0 primary duplicates\n",
        "#361116 + 0 mapped (99.94% : N/A)\n",
        "#358032 + 0 primary mapped (99.93% : N/A)\n",
        "#0 + 0 paired in sequencing\n",
        "#0 + 0 read1\n",
        "#0 + 0 read2\n",
        "#0 + 0 properly paired (N/A : N/A)\n",
        "#0 + 0 with itself and mate mapped\n",
        "#0 + 0 singletons (N/A : N/A)\n",
        "#0 + 0 with mate mapped to a different chr\n",
        "#0 + 0 with mate mapped to a different chr (mapQ>=5)\n",
        "```\n",
        "Now we have data about number of mapped reads - 358032.\n",
        "\n",
        "For data about average length of read we used python script. As first stage of analisis we gunzipped fastq file and then used belowlisted script.\n",
        "\n",
        "```python\n",
        "with open(\"<path_to_file>/SRR1705851.fastq\", \"r\") as file_input:\n",
        "    summator=[]\n",
        "\n",
        "# We calculate len of every second string. It isn't a problem, beacuse legths of second and fourth strings are equal.\n",
        "\n",
        "    for line in file_input:\n",
        "        string = file_input.readline().strip()\n",
        "        summator.append(len(string))\n",
        "    mean = sum(summator)/len(summator)\n",
        "    print(mean)\n",
        "\n",
        "    #147.14768118571448\n",
        "```\n",
        "\n",
        "We calculate the reference length by another script.\n",
        "\n",
        "```python    \n",
        "with open(\"<path_to_file>/sequence.fasta\", \"r\") as file_input:\n",
        "    summator = []\n",
        "    string = file_input.readline().strip()\n",
        "    print(len(string))\n",
        "!wc -m /sequence.fasta        \n",
        "\n",
        "#103\n",
        "#1794 <path_to_file>/sequence.fasta\n",
        "```\n",
        "\n",
        "Length of reference will be equal 1794 - 103 = 1691. Hence number we ssek is equal \n",
        "> (358032*147.15)/1691 = 31155.77\n",
        "\n",
        "31156 is a threshold we need to give to samtools mpileup.\n",
        "\n",
        "\n",
        "```bash\n",
        "samtools mpileup -d 32000 -f sequence.fasta sequence.SRR1705851.sorted.bam > my.mpileup\n",
        "```\n"
      ],
      "metadata": {
        "id": "FLtaIhN_X5fj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6. Variant calling.\n",
        "\n",
        "#### Substep 6.1. 95%\n",
        "\n",
        "For variant calling we used VarScan (v. 2.3.9).\n",
        "At the first stage we found most common SNPs (5) with 0.95 threshold.\n",
        "\n",
        "```bash\n",
        "java -jar <path_to_varscan>/VarScan.v2.3.9.jar  mpileup2snp my.mpileup --min-var-freq 0.95 --variants --output-vcf 1 > VarScan95_results.vcf\n",
        "\n",
        "\n",
        "\n",
        "#KF848938.1\t72\t.\tA\tG\t.\tPASS\tADP=16794;WT=0;HET=0;HOM=1;NC=0\tGT:GQ:SDP:DP:RD:AD:FREQ:PVAL:RBQ:ABQ:RDF:RDR:ADF:ADR\t1/1:255:16832:16794:6:16787:99.96%:0E0:35:36:4:2:10898:5889\n",
        "#KF848938.1\t117\t.\tC\tT\t.\tPASS\tADP=20254;WT=0;HET=0;HOM=1;NC=0\tGT:GQ:SDP:DP:RD:AD:FREQ:PVAL:RBQ:ABQ:RDF:RDR:ADF:ADR\t1/1:255:20352:20254:35:20217:99.82%:0E0:35:37:27:8:13382:6835\n",
        "#KF848938.1\t774\t.\tT\tC\t.\tPASS\tADP=30514;WT=0;HET=0;HOM=1;NC=0\tGT:GQ:SDP:DP:RD:AD:FREQ:PVAL:RBQ:ABQ:RDF:RDR:ADF:ADR\t1/1:255:30652:30514:5:30505:99.97%:0E0:34:37:5:0:17834:12671\n",
        "#KF848938.1\t999\t.\tC\tT\t.\tPASS\tADP=28797;WT=0;HET=0;HOM=1;NC=0\tGT:GQ:SDP:DP:RD:AD:FREQ:PVAL:RBQ:ABQ:RDF:RDR:ADF:ADR\t1/1:255:29226:28797:36:28756:99.86%:0E0:35:35:21:15:15647:13109\n",
        "#KF848938.1\t1260\t.\tA\tC\t.\tPASS\tADP=23033;WT=0;HET=0;HOM=1;NC=0\tGT:GQ:SDP:DP:RD:AD:FREQ:PVAL:RBQ:ABQ:RDF:RDR:ADF:ADR\t1/1:255:23067:23033:2:23019:99.94%:0E0:32:37:0:2:9824:13195\n",
        "```\n",
        "Or in more convinient format with awk:\n",
        "\n",
        "```bash\n",
        "cat VarScan95_results.vcf | awk 'NR>24 {print $1, $2, $4, $5}'\n",
        "\n",
        "\n",
        "#KF848938.1 72 A G\n",
        "#KF848938.1 117 C T\n",
        "#KF848938.1 774 T C\n",
        "#KF848938.1 999 C T\n",
        "#KF848938.1 1260 A C\n",
        "```\n",
        "\n",
        "For analysing mutations we used IGV.\n",
        "\n",
        "The first mutation was substitution of A for G. It substitutes of ACA triplet to ACG. It's a samesense-mutation, because the result of both triplet translation will be threonine.\n",
        "\n",
        "The second mutation was substitution of C for T. It substitutes of GCC triplet to GCT. It's a samesense-mutation, because the result of both triplet translation will be alanine.\n",
        "\n",
        "The third mutation was substitution of C for T. It substitutes of TTC triplet to TTT. It's a samesense-mutation, because the result of both triplet translation will be phenylalanine.\n",
        "\n",
        "The fourth mutation was substitution of C for T. It substitutes of GGC triplet to GGT. It's a samesense-mutation, because the result of both triplet translation will be glycine.\n",
        "\n",
        "The fifth mutation was substitution of A for C. It substitutes of CTA triplet to CTC. It's a samesense-mutation, because the result of both triplet translation will be leucine.\n",
        "\n",
        "As a result of first stage we have only five samesense mutations.\n"
      ],
      "metadata": {
        "id": "IpYKChD6F4CJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Substep 6.2. 0.1%\n",
        "\n",
        "We tried to find rare variants of SNPs.\n",
        "\n",
        "```bash\n",
        "java -jar ../../VarScan.v2.3.9.jar  mpileup2snp my.mpileup --min-var-freq 0.001 --variants --output-vcf 1 > VarScan01_results.vcf\n",
        "\n",
        "#KF848938.1\t72\t.\tA\tG\t.\tPASS\tADP=16794;WT=0;HET=0;HOM=1;NC=0\tGT:GQ:SDP:DP:RD:AD:FREQ:PVAL:RBQ:ABQ:RDF:RDR:ADF:ADR\t1/1:255:16832:16794:6:16787:99.96%:0E0:35:36:4:2:10898:5889\n",
        "#KF848938.1\t117\t.\tC\tT\t.\tPASS\tADP=20254;WT=0;HET=0;HOM=1;NC=0\tGT:GQ:SDP:DP:RD:AD:FREQ:PVAL:RBQ:ABQ:RDF:RDR:ADF:ADR\t1/1:255:20352:20254:35:20217:99.82%:0E0:35:37:27:8:13382:6835\n",
        "#KF848938.1\t254\t.\tA\tG\t.\tPASS\tADP=30830;WT=0;HET=1;HOM=0;NC=0\tGT:GQ:SDP:DP:RD:AD:FREQ:PVAL:RBQ:ABQ:RDF:RDR:ADF:ADR\t0/1:27:30963:30830:30767:58:0.19%:1.8611E-3:36:36:21003:9764:36:22\n",
        "#KF848938.1\t307\t.\tC\tT\t.\tPASS\tADP=28501;WT=0;HET=1;HOM=0;NC=0\tGT:GQ:SDP:DP:RD:AD:FREQ:PVAL:RBQ:ABQ:RDF:RDR:ADF:ADR\t0/1:255:28604:28501:28224:272:0.95%:6.6218E-52:36:35:17685:10539:144:128\n",
        "#KF848938.1\t340\t.\tT\tC\t.\tPASS\tADP=29279;WT=0;HET=1;HOM=0;NC=0\tGT:GQ:SDP:DP:RD:AD:FREQ:PVAL:RBQ:ABQ:RDF:RDR:ADF:ADR\t0/1:21:29423:29279:29223:52:0.18%:6.9669E-3:37:35:18790:10433:34:18\n",
        "#KF848938.1\t389\t.\tT\tC\t.\tPASS\tADP=26881;WT=0;HET=1;HOM=0;NC=0\tGT:GQ:SDP:DP:RD:AD:FREQ:PVAL:RBQ:ABQ:RDF:RDR:ADF:ADR\t0/1:39:27041:26881:26817:61:0.23%:1.1057E-4:37:36:14104:12713:41:20\n",
        "#KF848938.1\t722\t.\tA\tG\t.\tPASS\tADP=30017;WT=0;HET=1;HOM=0;NC=0\tGT:GQ:SDP:DP:RD:AD:FREQ:PVAL:RBQ:ABQ:RDF:RDR:ADF:ADR\t0/1:41:30041:30017:29944:68:0.23%:7.7136E-5:37:36:19654:10290:39:29\n",
        "#KF848938.1\t744\t.\tA\tG\t.\tPASS\tADP=30435;WT=0;HET=1;HOM=0;NC=0\tGT:GQ:SDP:DP:RD:AD:FREQ:PVAL:RBQ:ABQ:RDF:RDR:ADF:ADR\t0/1:23:30477:30435:30371:55:0.18%:4.3947E-3:37:32:19521:10850:33:22\n",
        "#KF848938.1\t774\t.\tT\tC\t.\tPASS\tADP=30514;WT=0;HET=0;HOM=1;NC=0\tGT:GQ:SDP:DP:RD:AD:FREQ:PVAL:RBQ:ABQ:RDF:RDR:ADF:ADR\t1/1:255:30652:30514:5:30505:99.97%:0E0:34:37:5:0:17834:12671\n",
        "#KF848938.1\t802\t.\tA\tG\t.\tPASS\tADP=31594;WT=0;HET=1;HOM=0;NC=0\tGT:GQ:SDP:DP:RD:AD:FREQ:PVAL:RBQ:ABQ:RDF:RDR:ADF:ADR\t0/1:52:31685:31594:31513:77:0.24%:5.4834E-6:37:35:18099:13414:28:49\n",
        "#KF848938.1\t915\t.\tT\tC\t.\tPASS\tADP=30957;WT=0;HET=1;HOM=0;NC=0\tGT:GQ:SDP:DP:RD:AD:FREQ:PVAL:RBQ:ABQ:RDF:RDR:ADF:ADR\t0/1:32:31055:30957:30887:62:0.2%:5.508E-4:35:35:16615:14272:35:27\n",
        "#KF848938.1\t999\t.\tC\tT\t.\tPASS\tADP=28797;WT=0;HET=0;HOM=1;NC=0\tGT:GQ:SDP:DP:RD:AD:FREQ:PVAL:RBQ:ABQ:RDF:RDR:ADF:ADR\t1/1:255:29226:28797:36:28756:99.86%:0E0:35:35:21:15:15647:13109\n",
        "#KF848938.1\t1043\t.\tA\tG\t.\tPASS\tADP=28440;WT=0;HET=1;HOM=0;NC=0\tGT:GQ:SDP:DP:RD:AD:FREQ:PVAL:RBQ:ABQ:RDF:RDR:ADF:ADR\t0/1:26:28483:28440:28382:55:0.19%:2.0064E-3:35:33:15882:12500:18:37\n",
        "#KF848938.1\t1086\t.\tA\tG\t.\tPASS\tADP=23991;WT=0;HET=1;HOM=0;NC=0\tGT:GQ:SDP:DP:RD:AD:FREQ:PVAL:RBQ:ABQ:RDF:RDR:ADF:ADR\t0/1:31:23992:23991:23938:51:0.21%:7.5186E-4:36:35:12540:11398:21:30\n",
        "#KF848938.1\t1213\t.\tA\tG\t.\tPASS\tADP=25093;WT=0;HET=1;HOM=0;NC=0\tGT:GQ:SDP:DP:RD:AD:FREQ:PVAL:RBQ:ABQ:RDF:RDR:ADF:ADR\t0/1:34:25177:25093:25035:56:0.22%:3.7244E-4:37:36:8964:16071:24:32\n",
        "#KF848938.1\t1260\t.\tA\tC\t.\tPASS\tADP=23033;WT=0;HET=0;HOM=1;NC=0\tGT:GQ:SDP:DP:RD:AD:FREQ:PVAL:RBQ:ABQ:RDF:RDR:ADF:ADR\t1/1:255:23067:23033:2:23019:99.94%:0E0:32:37:0:2:9824:13195\n",
        "#KF848938.1\t1280\t.\tT\tC\t.\tPASS\tADP=23462;WT=0;HET=1;HOM=0;NC=0\tGT:GQ:SDP:DP:RD:AD:FREQ:PVAL:RBQ:ABQ:RDF:RDR:ADF:ADR\t0/1:20:23487:23462:23418:43:0.18%:9.2875E-3:37:35:11147:12271:24:19\n",
        "#KF848938.1\t1458\t.\tT\tC\t.\tPASS\tADP=25707;WT=0;HET=1;HOM=0;NC=0\tGT:GQ:SDP:DP:RD:AD:FREQ:PVAL:RBQ:ABQ:RDF:RDR:ADF:ADR\t0/1:255:25838:25707:25490:214:0.83%:4.5784E-39:37:35:6834:18656:80:134\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "qPY7FXi7Z1Mn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7. Inspecting and aligning the control sample sequencing data\n",
        "\n",
        "We downloaded fastq data for three controls.\n",
        "\n",
        "```bash\n",
        "wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR170/008/SRR1705858/SRR1705858.fastq.gz\n",
        "wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR170/009/SRR1705859/SRR1705859.fastq.gz\n",
        "wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR170/000/SRR1705860/SRR1705860.fastq.gz \n",
        "```\n",
        "\n",
        "We calculated average genome coverage. The number of covered reads was 256500 in the first sample, 233251 in the second sample, 249888 in the third sample. Mean leangths of reads in fastq (calculated by above-described python script) are 148.56 for the first one, 148.45 for the second and 148.70 for the third.\n",
        "The average coverages are 22534.4, 20476.7 and 21974.2 respectively.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Then we aligned all three sequences on the reference, using described above snakemake script.\n",
        "\n",
        "```bash\n",
        "snakemake -p --cores all sequence.SRR1705858.sorted.bam\n",
        "snakemake -p --cores all sequence.SRR1705859.sorted.bam\n",
        "snakemake -p --cores all sequence.SRR1705860.sorted.bam\n",
        "```\n",
        "\n",
        "All alignments were indexed by smatools.\n",
        "\n",
        "```bash\n",
        "samtools index sequence.SRR1705858.sorted.bam\n",
        "samtools index sequence.SRR1705859.sorted.bam\n",
        "samtools index sequence.SRR1705860.sorted.bam\n",
        "```\n",
        "\n",
        "And then we used mpileup in a above-described manner. 23000 was chosen as a threshold, because it's quite higher then genome coverage of our three alignments.\n",
        "\n",
        "```bash\n",
        "samtools mpileup -d 23000 -f sequence.fasta sequence.SRR1705858.sorted.bam > my58.mpileup\n",
        "samtools mpileup -d 23000 -f sequence.fasta sequence.SRR1705859.sorted.bam > my59.mpileup\n",
        "samtools mpileup -d 23000 -f sequence.fasta sequence.SRR1705860.sorted.bam > my60.mpileup\n",
        "```\n",
        "\n",
        "At the next stage all alignments were elaborated with varscan.\n",
        "\n",
        "```bash\n",
        "java -jar ../../VarScan.v2.3.9.jar  mpileup2snp my58.mpileup --min-var-freq 0.001 --variants --output-vcf 1 > VarScan5801_results.vcf\n",
        "\n",
        "java -jar ../../VarScan.v2.3.9.jar  mpileup2snp my59.mpileup --min-var-freq 0.001 --variants --output-vcf 1 > VarScan5901_results.vcf\n",
        "\n",
        "java -jar ../../VarScan.v2.3.9.jar  mpileup2snp my60.mpileup --min-var-freq 0.001 --variants --output-vcf 1 > VarScan6001_results.vcf\n",
        "```\n",
        "\n",
        "For parsing our samples we created two TSV files for each vcf file: first contained data about reference, locus of substitution, and two nucleotids: before and after substitution, and second contained probability of this substitution. Then we combined them and computed two types of threshold - 1-tailed t-distribution with p=0.05 and 3 SDs from the each mean.\n",
        "\n",
        "```bash\n",
        "cat VarScan5801_results.vcf | awk -v FS=\"\\t\" -v OFS=\"\\t\" 'NR>24 {print $1, $2, $4, $5}' > positions58.tsv\n",
        "cat VarScan5901_results.vcf | awk -v FS=\"\\t\" -v OFS=\"\\t\" 'NR>24 {print $1, $2, $4, $5}' > positions59.tsv\n",
        "cat VarScan6001_results.vcf | awk -v FS=\"\\t\" -v OFS=\"\\t\" 'NR>24 {print $1, $2, $4, $5}' > positions60.tsv\n",
        "\n",
        "cat VarScan5801_results.vcf | awk 'NR>24 {print $10}' | awk -v FS=\":\" -v OFS=\"\\t\" '{print $7}' > possibility58.tsv\n",
        "cat VarScan5901_results.vcf | awk 'NR>24 {print $10}' | awk -v FS=\":\" -v OFS=\"\\t\" '{print $7}' > possibility59.tsv\n",
        "cat VarScan6001_results.vcf | awk 'NR>24 {print $10}' | awk -v FS=\":\" -v OFS=\"\\t\" '{print $7}' > possibility60.tsv\n",
        "```\n",
        "\n",
        "On the next stage we computed three means and three standard deviations of mutation probability.\n",
        "\n",
        "```R\n",
        "# Setting working directory\n",
        "setwd('<path_to_directory>')\n",
        "\n",
        "# Reading data\n",
        "nucl58 <- read.csv(\"positions58.tsv\", sep = \"\\t\", header = FALSE)\n",
        "nucl59 <- read.csv(\"positions59.tsv\", sep = \"\\t\", header = FALSE)\n",
        "nucl60 <- read.csv(\"positions60.tsv\", sep = \"\\t\", header = FALSE)\n",
        "prob58 <- read.csv(\"possibility58.tsv\", sep = \"\\t\", header = FALSE)\n",
        "prob59 <- read.csv(\"possibility59.tsv\", sep = \"\\t\", header = FALSE)\n",
        "prob60 <- read.csv(\"possibility60.tsv\", sep = \"\\t\", header = FALSE)\n",
        "\n",
        "# Removing \"%\" at the end of strings\n",
        "prob58 <- apply(prob58, 1, function(x) gsub(\"%\", \"\", x))\n",
        "prob59 <- apply(prob59, 1, function(x) gsub(\"%\", \"\", x))\n",
        "prob60 <- apply(prob60, 1, function(x) gsub(\"%\", \"\", x))\n",
        "\n",
        "# Merging tables\n",
        "result58 <- cbind(nucl58, prob58)\n",
        "result59 <- cbind(nucl59, prob59)\n",
        "result60 <- cbind(nucl60, prob60)\n",
        "\n",
        "# Transforming probability from strings to numerical data\n",
        "result58$prob58 <- as.double(result58$prob58)\n",
        "result59$prob59 <- as.double(result59$prob59)\n",
        "result60$prob60 <- as.double(result60$prob60)\n",
        "\n",
        "\n",
        "# Computing statistics and finding threshold for mutation probability\n",
        "mean(result58$prob58)\n",
        "sd(result58$prob58)\n",
        "\n",
        "critical58_1 = mean(result58$prob58)+(1.6741*(sd(result58$prob58)/(length(result58$prob58)**0.5)))\n",
        "critical58_1\n",
        "critical58_2 = mean(result58$prob58)+(sd(result58$prob58)*3)\n",
        "critical58_2\n",
        "\n",
        "mean(result59$prob59)\n",
        "sd(result59$prob59)\n",
        "\n",
        "critical59 = mean(result59$prob59)+(1.6772*(sd(result59$prob59)/(length(result59$prob59)**0.5)))\n",
        "critical59\n",
        "critical59_2 = mean(result59$prob59)+(sd(result59$prob59)*3)\n",
        "critical59_2\n",
        "\n",
        "\n",
        "mean(result60$prob60)\n",
        "sd(result60$prob60)\n",
        "\n",
        "critical60 = mean(result60$prob60)+(1.6725*(sd(result60$prob60)/(length(result60$prob60)**0.5)))\n",
        "critical60\n",
        "critical60_2 = mean(result60$prob60)+(sd(result60$prob60)*3)\n",
        "critical60_2\n",
        "\n",
        "\n",
        "\n",
        "# 0.2782936\n",
        "# 0.4761118\n",
        "# 0.2543942\n",
        "# 0.3967154\n",
        "# 0.2730022\n",
        "# 0.4932908\n",
        "```\n",
        "As a slightly paranoidal person, I use maximum value as a threshold for VarScan.\n",
        "\n",
        "We created new VCF file from experimental data with threshold 0.493. \n",
        "\n",
        "```bash\n",
        "java -jar ../../VarScan.v2.3.9.jar  mpileup2snp my.mpileup --min-var-freq 0.00493 --variants --output-vcf 1 > VarScan04_results.vcf\n",
        "```\n",
        "As a result, we have had 7 SNPs. 5 of them are high-frequency variants, that were analised before. For analysing two another SNPs we used IGV.\n",
        "\n",
        "The first mutation was substitution of C for T. It substitutes of CCG triplet to TCG. It's a missense-mutation, because the result of translation is serine instead of proline. This SNP is situated on the 307th nucleotide position, 103th aminoacid, epitope D of hemagglutinine.\n",
        "\n",
        "```\n",
        "KF848938.1:1-1653\n",
        "\n",
        "Type: gene\n",
        "ID: gene-HA\n",
        "Name: HA\n",
        "gbkey: Gene\n",
        "gene: HA\n",
        "gene_biotype: protein_coding\n",
        "partial: true\n",
        "start_range: .,1\n",
        "---------------------------\n",
        "Type: CDS\n",
        "ID: cds-AHB59323.1\n",
        "Parent: gene-HA\n",
        "Dbxref: NCBI_GP:AHB59323.1\n",
        "Name: AHB59323.1\n",
        "gbkey: CDS\n",
        "gene: HA\n",
        "partial: true\n",
        "product: hemagglutinin\n",
        "protein_id: AHB59323.1\n",
        "start_range: .,1\n",
        "```\n",
        "\n",
        "The second mutation was substitution of T for C. It substitutes of TAT triplet to TAC. It's a samesense-mutation, because the result of both triplet translation will be tyrosine.\n",
        "\n"
      ],
      "metadata": {
        "id": "3G6X_qB4fyUO"
      }
    }
  ]
}